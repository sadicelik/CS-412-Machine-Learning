{"cells":[{"metadata":{"_uuid":"f8f8af78-3351-445c-96e4-57ed1d0beb98","_cell_guid":"43959d7b-3e57-4441-ac40-bb058dfa9414","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt # plotting library, for simple plots\n","import seaborn as sns # plotting utility\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"execution_count":31,"outputs":[{"output_type":"stream","text":"/kaggle/input/cs412-fall2020/test.xlsx\n/kaggle/input/cs412-fall2020/sampleSubmission.csv\n/kaggle/input/cs412-fall2020/train.xlsx\n/kaggle/input/cs412-fall2020/dataset_explanation.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"74c81f2f-1628-4076-8f00-7a55326486ef","_cell_guid":"643d4ad9-ef4c-4159-859c-a74cfb9a18ce","trusted":true},"cell_type":"code","source":["train_df = pd.read_excel(\"../input/cs412-fall2020/train.xlsx\")\n","test_df = pd.read_excel(\"../input/cs412-fall2020/test.xlsx\")"],"execution_count":32,"outputs":[]},{"metadata":{"_uuid":"90ba8c44-530e-4324-9dfe-d777958de772","_cell_guid":"e58b77f0-a6f7-4e49-829d-73c9f53a1bc7","trusted":true},"cell_type":"markdown","source":["## Data Dictionary \n","__Demographic Features:__\n","* Gender, Country, Age, Employment Status\n","\n","__Education Features:__\n","* Formal Education, MajorSelect\n","\n","__Data Science Experience:__\n","* __Tenure:__ How long has the Kaggler been writing code to analyze data\n","* __MLSkillsSelect:__ In which areas of ML do the Kaggler consider herself/himself as competent\n","* __MLTechniquesSelect:__ In which techniques of ML do the person consider herself/himself as competent\n","* __CodeWriter:__ Whether the person writes code to analyze data\n","\n","__Features Related to Workplace:__\n","* CurrentEmployerType, EmployerIndustry, EmployerSize, CurrentJobTitleSelect, PastJobTitlesSelect , CompensationScore…\n","* __WorkAlgorithmsSelect:__ List of algorithms/analytic methods that are being typically used\n","* __TitleFit:__ How adequately the title describes what employee does.\n","* __RemoteWork:__ Frequency of working remotely.\n","* __WorkProductionFrequency:__ Frequency of models building to get put into production.\n","* __WorkToolsFrequency:__ How frequently does the Kaggler use the related tool?\n","* __WorkInternalVsExternalTools:__ Degree of the Kaggler’s team use internal versus external resources for data science projects.\n","* __WorkMLTeamSeatSelect:__ Sitting place of ML team in the office.\n","* __WorkDataVisualizations:__ Proportion of analytics projects that incorporate data visualization.\n","\n","__Other Features:__\n","* __MLToolNextYearSelect:__ Tools and technologies that the Kaggler most excited about learning in the next year.\n","* __MLMethodNextYearSelect:__ ML/DS methods that the Kaggler most exiced about learning next year.\n","* __LanguageRecommendationSelect:__ Recommendation of a programming language for a new data scientist.\n","* __LearningPlatformUsefulness:__ Usefulness of related platforms & resources for learning data science skills.\n","* __DataScienceIdentitySelect:__ Is the Kaggler consider herself/himself as a data scientist?"]},{"metadata":{"_uuid":"59e3ca91-568c-4fc7-9161-7fb87ea2e053","_cell_guid":"d693de79-37d9-4e28-996b-2ebc02d085f0","trusted":true},"cell_type":"markdown","source":["## Train Dataset"]},{"metadata":{"_uuid":"6f2cd93b-d088-4e41-af54-18ea493c7644","_cell_guid":"4cda3676-b6db-4c71-8cbf-1f161ce4038d","trusted":true},"cell_type":"code","source":["# There are 5529 records (rows) with 54 features (columns)\n","train_df.shape"],"execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"(5529, 54)"},"metadata":{}}]},{"metadata":{"_uuid":"16605dc8-a50e-462b-83f1-4bcfd3153bb8","_cell_guid":"3e6649ae-47c2-4666-afac-2ba871780e06","trusted":true},"cell_type":"code","source":["# Detailed information of the dataframe can be seen here\n","train_df.info()"],"execution_count":34,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5529 entries, 0 to 5528\nData columns (total 54 columns):\n #   Column                                  Non-Null Count  Dtype  \n---  ------                                  --------------  -----  \n 0   ID                                      5529 non-null   int64  \n 1   GenderSelect                            5519 non-null   object \n 2   Country                                 5513 non-null   object \n 3   Age                                     5461 non-null   float64\n 4   EmploymentStatus                        5529 non-null   object \n 5   CodeWriter                              5529 non-null   object \n 6   CurrentJobTitleSelect                   5527 non-null   object \n 7   TitleFit                                5427 non-null   object \n 8   CurrentEmployerType                     5458 non-null   object \n 9   MLToolNextYearSelect                    5298 non-null   object \n 10  MLMethodNextYearSelect                  5252 non-null   object \n 11  LanguageRecommendationSelect            5334 non-null   object \n 12  LearningPlatformUsefulnessBlogs         2531 non-null   object \n 13  LearningPlatformUsefulnessKaggle        3168 non-null   object \n 14  LearningPlatformUsefulnessCourses       2941 non-null   object \n 15  LearningPlatformUsefulnessProjects      2499 non-null   object \n 16  LearningPlatformUsefulnessSO            2996 non-null   object \n 17  LearningPlatformUsefulnessTextbook      2202 non-null   object \n 18  LearningPlatformUsefulnessYouTube       2413 non-null   object \n 19  DataScienceIdentitySelect               3984 non-null   object \n 20  FormalEducation                         5522 non-null   object \n 21  MajorSelect                             5010 non-null   object \n 22  Tenure                                  5515 non-null   object \n 23  PastJobTitlesSelect                     5324 non-null   object \n 24  MLSkillsSelect                          5256 non-null   object \n 25  MLTechniquesSelect                      5218 non-null   object \n 26  EmployerIndustry                        5517 non-null   object \n 27  EmployerSize                            4948 non-null   object \n 28  WorkProductionFrequency                 4903 non-null   object \n 29  WorkAlgorithmsSelect                    5103 non-null   object \n 30  WorkToolsFrequencyPython                4247 non-null   object \n 31  WorkToolsFrequencyR                     3357 non-null   object \n 32  WorkToolsFrequencySQL                   3000 non-null   object \n 33  WorkMethodsFrequencyCross-Validation    2802 non-null   object \n 34  WorkMethodsFrequencyDataVisualization   3620 non-null   object \n 35  WorkMethodsFrequencyDecisionTrees       2654 non-null   object \n 36  WorkMethodsFrequencyLogisticRegression  3126 non-null   object \n 37  WorkMethodsFrequencyNeuralNetworks      1967 non-null   object \n 38  WorkMethodsFrequencyPCA                 2046 non-null   object \n 39  WorkMethodsFrequencyRandomForests       2502 non-null   object \n 40  WorkMethodsFrequencyTimeSeriesAnalysis  2294 non-null   object \n 41  WorkChallengeFrequencyPolitics          2092 non-null   object \n 42  WorkChallengeFrequencyUnusedResults     1360 non-null   object \n 43  WorkChallengeFrequencyDirtyData         2769 non-null   object \n 44  WorkChallengeFrequencyExplaining        1250 non-null   object \n 45  WorkChallengeFrequencyTalent            2366 non-null   object \n 46  WorkChallengeFrequencyClarity           1724 non-null   object \n 47  WorkChallengeFrequencyDataAccess        1720 non-null   object \n 48  CompensationScore                       4373 non-null   float64\n 49  WorkDataVisualizations                  5500 non-null   object \n 50  WorkInternalVsExternalTools             5413 non-null   object \n 51  WorkMLTeamSeatSelect                    5367 non-null   object \n 52  RemoteWork                              4947 non-null   object \n 53  JobSatisfaction                         5529 non-null   int64  \ndtypes: float64(2), int64(2), object(50)\nmemory usage: 2.3+ MB\n","name":"stdout"}]},{"metadata":{"_uuid":"c9489026-a50d-4e82-938e-9cd6795c3b4f","_cell_guid":"749beead-4971-44dc-92ec-16cc0b817f2e","trusted":true},"cell_type":"code","source":["# There are many missing values for the features.\n","# Missing value per feature can be seen here\n","train_df.isnull().sum()"],"execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"ID                                           0\nGenderSelect                                10\nCountry                                     16\nAge                                         68\nEmploymentStatus                             0\nCodeWriter                                   0\nCurrentJobTitleSelect                        2\nTitleFit                                   102\nCurrentEmployerType                         71\nMLToolNextYearSelect                       231\nMLMethodNextYearSelect                     277\nLanguageRecommendationSelect               195\nLearningPlatformUsefulnessBlogs           2998\nLearningPlatformUsefulnessKaggle          2361\nLearningPlatformUsefulnessCourses         2588\nLearningPlatformUsefulnessProjects        3030\nLearningPlatformUsefulnessSO              2533\nLearningPlatformUsefulnessTextbook        3327\nLearningPlatformUsefulnessYouTube         3116\nDataScienceIdentitySelect                 1545\nFormalEducation                              7\nMajorSelect                                519\nTenure                                      14\nPastJobTitlesSelect                        205\nMLSkillsSelect                             273\nMLTechniquesSelect                         311\nEmployerIndustry                            12\nEmployerSize                               581\nWorkProductionFrequency                    626\nWorkAlgorithmsSelect                       426\nWorkToolsFrequencyPython                  1282\nWorkToolsFrequencyR                       2172\nWorkToolsFrequencySQL                     2529\nWorkMethodsFrequencyCross-Validation      2727\nWorkMethodsFrequencyDataVisualization     1909\nWorkMethodsFrequencyDecisionTrees         2875\nWorkMethodsFrequencyLogisticRegression    2403\nWorkMethodsFrequencyNeuralNetworks        3562\nWorkMethodsFrequencyPCA                   3483\nWorkMethodsFrequencyRandomForests         3027\nWorkMethodsFrequencyTimeSeriesAnalysis    3235\nWorkChallengeFrequencyPolitics            3437\nWorkChallengeFrequencyUnusedResults       4169\nWorkChallengeFrequencyDirtyData           2760\nWorkChallengeFrequencyExplaining          4279\nWorkChallengeFrequencyTalent              3163\nWorkChallengeFrequencyClarity             3805\nWorkChallengeFrequencyDataAccess          3809\nCompensationScore                         1156\nWorkDataVisualizations                      29\nWorkInternalVsExternalTools                116\nWorkMLTeamSeatSelect                       162\nRemoteWork                                 582\nJobSatisfaction                              0\ndtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"924ce741-2655-4c03-a5f5-3b2f0ee30e9a","_cell_guid":"886cd7bd-0de2-424c-a173-d469eaebbd90","trusted":true},"cell_type":"code","source":["train_df.head()"],"execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"   ID GenderSelect        Country   Age  \\\n0   1         Male       Pakistan  28.0   \n1   2         Male         Mexico  26.0   \n2   3       Female  United States  34.0   \n3   4       Female  United States  33.0   \n4   5       Female  United States  35.0   \n\n                                    EmploymentStatus CodeWriter  \\\n0  Independent contractor, freelancer, or self-em...        Yes   \n1                                 Employed full-time        Yes   \n2                                 Employed full-time        Yes   \n3                                 Employed full-time        Yes   \n4                                 Employed full-time        Yes   \n\n                  CurrentJobTitleSelect TitleFit  \\\n0  Software Developer/Software Engineer     Fine   \n1                    Computer Scientist   Poorly   \n2                          Data Analyst     Fine   \n3                  Scientist/Researcher     Fine   \n4  Software Developer/Software Engineer     Fine   \n\n                                 CurrentEmployerType  \\\n0                                      Self-employed   \n1  Employed by a company that doesn't perform adv...   \n2                             Employed by government   \n3                  Employed by college or university   \n4  Employed by a company that performs advanced a...   \n\n           MLToolNextYearSelect  ... WorkChallengeFrequencyExplaining  \\\n0                        Python  ...                              NaN   \n1                        Python  ...                              NaN   \n2                    TensorFlow  ...                              NaN   \n3  IBM Watson / Waton Analytics  ...                              NaN   \n4          Google Cloud Compute  ...                              NaN   \n\n  WorkChallengeFrequencyTalent WorkChallengeFrequencyClarity  \\\n0                          NaN                           NaN   \n1                        Often                           NaN   \n2                    Sometimes                           NaN   \n3                          NaN                        Rarely   \n4                          NaN                           NaN   \n\n  WorkChallengeFrequencyDataAccess CompensationScore WorkDataVisualizations  \\\n0                              NaN               8.0     51-75% of projects   \n1                              NaN               NaN       100% of projects   \n2                 Most of the time               2.0     10-25% of projects   \n3                           Rarely               2.0     76-99% of projects   \n4                        Sometimes               8.0       100% of projects   \n\n                     WorkInternalVsExternalTools WorkMLTeamSeatSelect  \\\n0  Approximately half internal and half external      Standalone Team   \n1                    More internal than external  Business Department   \n2                    More internal than external                Other   \n3                                    Do not know                Other   \n4                              Entirely internal                Other   \n\n  RemoteWork JobSatisfaction  \n0        NaN               4  \n1        NaN               7  \n2     Rarely               6  \n3     Rarely               9  \n4     Rarely               8  \n\n[5 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>GenderSelect</th>\n      <th>Country</th>\n      <th>Age</th>\n      <th>EmploymentStatus</th>\n      <th>CodeWriter</th>\n      <th>CurrentJobTitleSelect</th>\n      <th>TitleFit</th>\n      <th>CurrentEmployerType</th>\n      <th>MLToolNextYearSelect</th>\n      <th>...</th>\n      <th>WorkChallengeFrequencyExplaining</th>\n      <th>WorkChallengeFrequencyTalent</th>\n      <th>WorkChallengeFrequencyClarity</th>\n      <th>WorkChallengeFrequencyDataAccess</th>\n      <th>CompensationScore</th>\n      <th>WorkDataVisualizations</th>\n      <th>WorkInternalVsExternalTools</th>\n      <th>WorkMLTeamSeatSelect</th>\n      <th>RemoteWork</th>\n      <th>JobSatisfaction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Male</td>\n      <td>Pakistan</td>\n      <td>28.0</td>\n      <td>Independent contractor, freelancer, or self-em...</td>\n      <td>Yes</td>\n      <td>Software Developer/Software Engineer</td>\n      <td>Fine</td>\n      <td>Self-employed</td>\n      <td>Python</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>51-75% of projects</td>\n      <td>Approximately half internal and half external</td>\n      <td>Standalone Team</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Male</td>\n      <td>Mexico</td>\n      <td>26.0</td>\n      <td>Employed full-time</td>\n      <td>Yes</td>\n      <td>Computer Scientist</td>\n      <td>Poorly</td>\n      <td>Employed by a company that doesn't perform adv...</td>\n      <td>Python</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>Often</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100% of projects</td>\n      <td>More internal than external</td>\n      <td>Business Department</td>\n      <td>NaN</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Female</td>\n      <td>United States</td>\n      <td>34.0</td>\n      <td>Employed full-time</td>\n      <td>Yes</td>\n      <td>Data Analyst</td>\n      <td>Fine</td>\n      <td>Employed by government</td>\n      <td>TensorFlow</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>Sometimes</td>\n      <td>NaN</td>\n      <td>Most of the time</td>\n      <td>2.0</td>\n      <td>10-25% of projects</td>\n      <td>More internal than external</td>\n      <td>Other</td>\n      <td>Rarely</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Female</td>\n      <td>United States</td>\n      <td>33.0</td>\n      <td>Employed full-time</td>\n      <td>Yes</td>\n      <td>Scientist/Researcher</td>\n      <td>Fine</td>\n      <td>Employed by college or university</td>\n      <td>IBM Watson / Waton Analytics</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Rarely</td>\n      <td>Rarely</td>\n      <td>2.0</td>\n      <td>76-99% of projects</td>\n      <td>Do not know</td>\n      <td>Other</td>\n      <td>Rarely</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Female</td>\n      <td>United States</td>\n      <td>35.0</td>\n      <td>Employed full-time</td>\n      <td>Yes</td>\n      <td>Software Developer/Software Engineer</td>\n      <td>Fine</td>\n      <td>Employed by a company that performs advanced a...</td>\n      <td>Google Cloud Compute</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Sometimes</td>\n      <td>8.0</td>\n      <td>100% of projects</td>\n      <td>Entirely internal</td>\n      <td>Other</td>\n      <td>Rarely</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 54 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"8fd1e4eb-721a-446d-b380-0f51a3515a14","_cell_guid":"4b69a2f1-4fd2-4577-a7c0-bdfffe8a72c7","trusted":true},"cell_type":"code","source":["# Creating a prediction dataframe for submission csv\n","pred_df = pd.DataFrame(test_df[\"ID\"], columns=[\"ID\"])"],"execution_count":37,"outputs":[]},{"metadata":{"_uuid":"9bce058b-9948-4860-ab79-e2a17ed32cf5","_cell_guid":"4fba49a4-8796-4768-acff-ee0d13ffcb52","trusted":true},"cell_type":"code","source":["# \"ID\" column is irrelevant\n","# \"CodeWriter\" columns only contain \"Yes\" answer, that is why not an effective column\n","train_df.drop(columns=[\"CodeWriter\", \"ID\"], inplace=True)"],"execution_count":38,"outputs":[]},{"metadata":{"_uuid":"0913ce5b-05bc-495c-89dd-1f9e947ec333","_cell_guid":"47f6f57a-117d-47b5-a2f5-56cb26dca13c","trusted":true},"cell_type":"code","source":["# Filling empty row in columns with their modes and means\n","train_df[\"GenderSelect\"].fillna(train_df[\"GenderSelect\"].mode()[0], inplace=True)\n","train_df[\"Country\"].fillna(train_df[\"Country\"].mode()[0], inplace=True)\n","train_df[\"Age\"].fillna(np.floor(train_df[\"Age\"].mean()), inplace=True)\n","train_df[\"CurrentJobTitleSelect\"].fillna(train_df[\"CurrentJobTitleSelect\"].mode()[0], inplace=True)\n","train_df[\"TitleFit\"].fillna(train_df[\"TitleFit\"].mode()[0], inplace=True)\n","train_df[\"CurrentEmployerType\"].fillna(train_df[\"CurrentEmployerType\"].mode()[0], inplace=True)\n","train_df[\"DataScienceIdentitySelect\"].fillna(train_df[\"DataScienceIdentitySelect\"].mode()[0], inplace=True)\n","train_df[\"FormalEducation\"].fillna(train_df[\"FormalEducation\"].mode()[0], inplace=True)\n","train_df[\"MajorSelect\"].fillna(train_df[\"MajorSelect\"].mode()[0], inplace=True)\n","train_df[\"Tenure\"].fillna(train_df[\"Tenure\"].mode()[0], inplace=True)\n","train_df[\"PastJobTitlesSelect\"].fillna(train_df[\"PastJobTitlesSelect\"].mode()[0], inplace=True)\n","train_df[\"MLSkillsSelect\"].fillna(train_df[\"MLSkillsSelect\"].mode()[0], inplace=True)              \n","train_df[\"MLTechniquesSelect\"].fillna(train_df[\"MLTechniquesSelect\"].mode()[0], inplace=True)\n","train_df[\"EmployerIndustry\"].fillna(train_df[\"EmployerIndustry\"].mode()[0], inplace=True)\n","train_df[\"EmployerSize\"].fillna(train_df[\"EmployerSize\"].mode()[0], inplace=True)\n","train_df[\"WorkProductionFrequency\"].fillna(train_df[\"WorkProductionFrequency\"].mode()[0], inplace=True)\n","train_df[\"WorkAlgorithmsSelect\"].fillna(train_df[\"WorkAlgorithmsSelect\"].mode()[0], inplace=True)\n","train_df[\"CompensationScore\"].fillna(np.floor(train_df[\"CompensationScore\"].mean()), inplace=True)\n","train_df[\"WorkDataVisualizations\"].fillna(train_df[\"WorkDataVisualizations\"].mode()[0], inplace=True)\n","train_df[\"WorkMLTeamSeatSelect\"].fillna(train_df[\"WorkMLTeamSeatSelect\"].mode()[0], inplace=True)\n","train_df[\"RemoteWork\"].fillna(train_df[\"RemoteWork\"].mode()[0], inplace=True)\n","\n","# Below columns contains high amount of NaN values\n","train_df[\"MLToolNextYearSelect\"].fillna(train_df[\"MLToolNextYearSelect\"].mode()[0], inplace=True)\n","train_df[\"MLMethodNextYearSelect\"].fillna(train_df[\"MLMethodNextYearSelect\"].mode()[0], inplace=True)\n","train_df[\"LanguageRecommendationSelect\"].fillna(train_df[\"LanguageRecommendationSelect\"].mode()[0], inplace=True)\n","train_df[\"WorkInternalVsExternalTools\"].fillna(value=\"Do not know\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessBlogs\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessKaggle\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessCourses\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessProjects\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessSO\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessTextbook\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"LearningPlatformUsefulnessYouTube\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkToolsFrequencyPython\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkToolsFrequencyR\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkToolsFrequencySQL\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyCross-Validation\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyDataVisualization\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyDecisionTrees\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyLogisticRegression\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyNeuralNetworks\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyPCA\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyRandomForests\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkMethodsFrequencyTimeSeriesAnalysis\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyPolitics\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyUnusedResults\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyDirtyData\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyExplaining\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyTalent\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyClarity\"].fillna(value=\"Zero\", inplace=True)\n","train_df[\"WorkChallengeFrequencyDataAccess\"].fillna(value=\"Zero\", inplace=True)\n","\n","# After the filling operation, show missing values in columns\n","train_df.isnull().sum()"],"execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"GenderSelect                              0\nCountry                                   0\nAge                                       0\nEmploymentStatus                          0\nCurrentJobTitleSelect                     0\nTitleFit                                  0\nCurrentEmployerType                       0\nMLToolNextYearSelect                      0\nMLMethodNextYearSelect                    0\nLanguageRecommendationSelect              0\nLearningPlatformUsefulnessBlogs           0\nLearningPlatformUsefulnessKaggle          0\nLearningPlatformUsefulnessCourses         0\nLearningPlatformUsefulnessProjects        0\nLearningPlatformUsefulnessSO              0\nLearningPlatformUsefulnessTextbook        0\nLearningPlatformUsefulnessYouTube         0\nDataScienceIdentitySelect                 0\nFormalEducation                           0\nMajorSelect                               0\nTenure                                    0\nPastJobTitlesSelect                       0\nMLSkillsSelect                            0\nMLTechniquesSelect                        0\nEmployerIndustry                          0\nEmployerSize                              0\nWorkProductionFrequency                   0\nWorkAlgorithmsSelect                      0\nWorkToolsFrequencyPython                  0\nWorkToolsFrequencyR                       0\nWorkToolsFrequencySQL                     0\nWorkMethodsFrequencyCross-Validation      0\nWorkMethodsFrequencyDataVisualization     0\nWorkMethodsFrequencyDecisionTrees         0\nWorkMethodsFrequencyLogisticRegression    0\nWorkMethodsFrequencyNeuralNetworks        0\nWorkMethodsFrequencyPCA                   0\nWorkMethodsFrequencyRandomForests         0\nWorkMethodsFrequencyTimeSeriesAnalysis    0\nWorkChallengeFrequencyPolitics            0\nWorkChallengeFrequencyUnusedResults       0\nWorkChallengeFrequencyDirtyData           0\nWorkChallengeFrequencyExplaining          0\nWorkChallengeFrequencyTalent              0\nWorkChallengeFrequencyClarity             0\nWorkChallengeFrequencyDataAccess          0\nCompensationScore                         0\nWorkDataVisualizations                    0\nWorkInternalVsExternalTools               0\nWorkMLTeamSeatSelect                      0\nRemoteWork                                0\nJobSatisfaction                           0\ndtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"be180692-72bb-46e3-a567-4432a98d9348","_cell_guid":"728da120-00c4-4716-a90a-bbe7fa6c9992","trusted":true},"cell_type":"markdown","source":["## Test Dataset"]},{"metadata":{"_uuid":"ed627a9d-3930-4f2b-b2fa-c6c0a85ec950","_cell_guid":"72adb08d-54ae-4aa3-9b68-13f65b8716ee","trusted":true},"cell_type":"code","source":["# There are 1000 records \"rows\" with 53 features \"columns\" 1 feature \"JobSatisfaction\" was dropped\n","test_df.shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"(1000, 53)"},"metadata":{}}]},{"metadata":{"_uuid":"eaea7cb8-57af-49f1-b69c-8e95f087ae7e","_cell_guid":"808f4b0e-93e6-4068-b7fa-3f5d83f7714d","trusted":true},"cell_type":"code","source":["# There are also missing values for the features in the test data that needs to be filled\n","# Missing value per feature can be seen here\n","test_df.isnull().sum()"],"execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"ID                                          0\nGenderSelect                                2\nCountry                                     2\nAge                                        14\nEmploymentStatus                            0\nCodeWriter                                  0\nCurrentJobTitleSelect                       0\nTitleFit                                   20\nCurrentEmployerType                        14\nMLToolNextYearSelect                       44\nMLMethodNextYearSelect                     47\nLanguageRecommendationSelect               38\nLearningPlatformUsefulnessBlogs           547\nLearningPlatformUsefulnessKaggle          396\nLearningPlatformUsefulnessCourses         491\nLearningPlatformUsefulnessProjects        552\nLearningPlatformUsefulnessSO              449\nLearningPlatformUsefulnessTextbook        595\nLearningPlatformUsefulnessYouTube         534\nDataScienceIdentitySelect                 265\nFormalEducation                             1\nMajorSelect                                74\nTenure                                      1\nPastJobTitlesSelect                        32\nMLSkillsSelect                             42\nMLTechniquesSelect                         49\nEmployerIndustry                            2\nEmployerSize                              102\nWorkProductionFrequency                   107\nWorkAlgorithmsSelect                       71\nWorkToolsFrequencyPython                  221\nWorkToolsFrequencyR                       421\nWorkToolsFrequencySQL                     436\nWorkMethodsFrequencyCross-Validation      475\nWorkMethodsFrequencyDataVisualization     317\nWorkMethodsFrequencyDecisionTrees         503\nWorkMethodsFrequencyLogisticRegression    442\nWorkMethodsFrequencyNeuralNetworks        639\nWorkMethodsFrequencyPCA                   630\nWorkMethodsFrequencyRandomForests         524\nWorkMethodsFrequencyTimeSeriesAnalysis    600\nWorkChallengeFrequencyPolitics            616\nWorkChallengeFrequencyUnusedResults       739\nWorkChallengeFrequencyDirtyData           488\nWorkChallengeFrequencyExplaining          766\nWorkChallengeFrequencyTalent              585\nWorkChallengeFrequencyClarity             688\nWorkChallengeFrequencyDataAccess          692\nCompensationScore                         255\nWorkDataVisualizations                      8\nWorkInternalVsExternalTools                11\nWorkMLTeamSeatSelect                       29\nRemoteWork                                 99\ndtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"34f61a9b-8d42-41ce-8f38-dc2f25787e36","_cell_guid":"2fdeb055-ff00-469c-93db-2a2bf128d8c0","trusted":true},"cell_type":"code","source":["# \"ID\" column is irrelevant\n","# \"CodeWriter\" columns only contain \"Yes\" answer, that is why not an effective column\n","test_df.drop(columns=[\"CodeWriter\", \"ID\"], inplace=True)"],"execution_count":42,"outputs":[]},{"metadata":{"_uuid":"a3ce2091-f5b3-4256-91f8-77cfc6ea74f9","_cell_guid":"5b0c1f15-8b96-4170-be52-350928c9ff48","trusted":true},"cell_type":"code","source":["# Filling empty row in columns with their modes and means in the train data\n","test_df[\"GenderSelect\"].fillna(train_df[\"GenderSelect\"].mode()[0], inplace=True)\n","test_df[\"Country\"].fillna(train_df[\"Country\"].mode()[0], inplace=True)\n","test_df[\"Age\"].fillna(np.floor(train_df[\"Age\"].mean()), inplace=True)\n","test_df[\"CurrentJobTitleSelect\"].fillna(train_df[\"CurrentJobTitleSelect\"].mode()[0], inplace=True)\n","test_df[\"TitleFit\"].fillna(train_df[\"TitleFit\"].mode()[0], inplace=True)\n","test_df[\"CurrentEmployerType\"].fillna(train_df[\"CurrentEmployerType\"].mode()[0], inplace=True)\n","test_df[\"DataScienceIdentitySelect\"].fillna(train_df[\"DataScienceIdentitySelect\"].mode()[0], inplace=True)\n","test_df[\"FormalEducation\"].fillna(train_df[\"FormalEducation\"].mode()[0], inplace=True)\n","test_df[\"MajorSelect\"].fillna(train_df[\"MajorSelect\"].mode()[0], inplace=True)\n","test_df[\"Tenure\"].fillna(train_df[\"Tenure\"].mode()[0], inplace=True)\n","test_df[\"PastJobTitlesSelect\"].fillna(train_df[\"PastJobTitlesSelect\"].mode()[0], inplace=True)\n","test_df[\"MLSkillsSelect\"].fillna(train_df[\"MLSkillsSelect\"].mode()[0], inplace=True)              \n","test_df[\"MLTechniquesSelect\"].fillna(train_df[\"MLTechniquesSelect\"].mode()[0], inplace=True)\n","test_df[\"EmployerIndustry\"].fillna(train_df[\"EmployerIndustry\"].mode()[0], inplace=True)\n","test_df[\"EmployerSize\"].fillna(train_df[\"EmployerSize\"].mode()[0], inplace=True)\n","test_df[\"WorkProductionFrequency\"].fillna(train_df[\"WorkProductionFrequency\"].mode()[0], inplace=True)\n","test_df[\"WorkAlgorithmsSelect\"].fillna(train_df[\"WorkAlgorithmsSelect\"].mode()[0], inplace=True)\n","test_df[\"CompensationScore\"].fillna(np.floor(train_df[\"CompensationScore\"].mean()), inplace=True)\n","test_df[\"WorkDataVisualizations\"].fillna(train_df[\"WorkDataVisualizations\"].mode()[0], inplace=True)\n","test_df[\"WorkMLTeamSeatSelect\"].fillna(train_df[\"WorkMLTeamSeatSelect\"].mode()[0], inplace=True)\n","test_df[\"RemoteWork\"].fillna(train_df[\"RemoteWork\"].mode()[0], inplace=True)\n","\n","# Below columns contains high amount of NaN values\n","test_df[\"MLToolNextYearSelect\"].fillna(train_df[\"MLToolNextYearSelect\"].mode()[0], inplace=True)\n","test_df[\"MLMethodNextYearSelect\"].fillna(train_df[\"MLMethodNextYearSelect\"].mode()[0], inplace=True)\n","test_df[\"LanguageRecommendationSelect\"].fillna(train_df[\"LanguageRecommendationSelect\"].mode()[0], inplace=True)\n","test_df[\"WorkInternalVsExternalTools\"].fillna(value=\"Do not know\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessBlogs\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessKaggle\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessCourses\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessProjects\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessSO\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessTextbook\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"LearningPlatformUsefulnessYouTube\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkToolsFrequencyPython\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkToolsFrequencyR\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkToolsFrequencySQL\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyCross-Validation\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyDataVisualization\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyDecisionTrees\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyLogisticRegression\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyNeuralNetworks\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyPCA\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyRandomForests\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkMethodsFrequencyTimeSeriesAnalysis\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyPolitics\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyUnusedResults\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyDirtyData\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyExplaining\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyTalent\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyClarity\"].fillna(value=\"Zero\", inplace=True)\n","test_df[\"WorkChallengeFrequencyDataAccess\"].fillna(value=\"Zero\", inplace=True)\n","\n","# After the filling operation, show missing values in columns\n","test_df.isnull().sum()"],"execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"GenderSelect                              0\nCountry                                   0\nAge                                       0\nEmploymentStatus                          0\nCurrentJobTitleSelect                     0\nTitleFit                                  0\nCurrentEmployerType                       0\nMLToolNextYearSelect                      0\nMLMethodNextYearSelect                    0\nLanguageRecommendationSelect              0\nLearningPlatformUsefulnessBlogs           0\nLearningPlatformUsefulnessKaggle          0\nLearningPlatformUsefulnessCourses         0\nLearningPlatformUsefulnessProjects        0\nLearningPlatformUsefulnessSO              0\nLearningPlatformUsefulnessTextbook        0\nLearningPlatformUsefulnessYouTube         0\nDataScienceIdentitySelect                 0\nFormalEducation                           0\nMajorSelect                               0\nTenure                                    0\nPastJobTitlesSelect                       0\nMLSkillsSelect                            0\nMLTechniquesSelect                        0\nEmployerIndustry                          0\nEmployerSize                              0\nWorkProductionFrequency                   0\nWorkAlgorithmsSelect                      0\nWorkToolsFrequencyPython                  0\nWorkToolsFrequencyR                       0\nWorkToolsFrequencySQL                     0\nWorkMethodsFrequencyCross-Validation      0\nWorkMethodsFrequencyDataVisualization     0\nWorkMethodsFrequencyDecisionTrees         0\nWorkMethodsFrequencyLogisticRegression    0\nWorkMethodsFrequencyNeuralNetworks        0\nWorkMethodsFrequencyPCA                   0\nWorkMethodsFrequencyRandomForests         0\nWorkMethodsFrequencyTimeSeriesAnalysis    0\nWorkChallengeFrequencyPolitics            0\nWorkChallengeFrequencyUnusedResults       0\nWorkChallengeFrequencyDirtyData           0\nWorkChallengeFrequencyExplaining          0\nWorkChallengeFrequencyTalent              0\nWorkChallengeFrequencyClarity             0\nWorkChallengeFrequencyDataAccess          0\nCompensationScore                         0\nWorkDataVisualizations                    0\nWorkInternalVsExternalTools               0\nWorkMLTeamSeatSelect                      0\nRemoteWork                                0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["## Transforming Variables"]},{"metadata":{"_uuid":"c8d42cfe-9f87-4a74-8259-5a4f8af93cb0","_cell_guid":"ff7acf01-a698-4857-be82-e58f380b6f12","trusted":true},"cell_type":"markdown","source":["### 1. Ordinal Variables - Feature Mapping"]},{"metadata":{"_uuid":"a1ce9f0d-f957-4b16-ba99-1be606330af9","_cell_guid":"1040a1df-9919-40b5-8e00-365b51913155","trusted":true},"cell_type":"code","source":["# \"TitlesFits\" Mapping\n","titlefits_map = {'Poorly': 0, 'Fine': 1, 'Perfectly': 2}\n","train_df['TitleFit'] = train_df['TitleFit'].replace(titlefits_map)\n","test_df['TitleFit'] = test_df['TitleFit'].replace(titlefits_map)\n","\n","# \"FormalEducation\" Mapping\n","formaleducation_map = {'I prefer not to answer': 0, 'I did not complete any formal education past high school': 1, \"Some college/university study without earning a bachelor's degree\": 2,\n","                       'Professional degree': 3,\"Bachelor's degree\": 4,\"Master's degree\": 5,\"Doctoral degree\":6}\n","train_df['FormalEducation'] = train_df['FormalEducation'].replace(formaleducation_map)\n","test_df['FormalEducation'] = test_df['FormalEducation'].replace(formaleducation_map)\n","\n","# \"Tenure\" Mapping\n","tenure_map = {\"I don't write code to analyze data\": 0, 'Less than a year': 1, '1 to 2 years': 2, '3 to 5 years': 3, '6 to 10 years': 4, 'More than 10 years': 5}\n","train_df['Tenure'] = train_df['Tenure'].replace(tenure_map)\n","test_df['Tenure'] = test_df['Tenure'].replace(tenure_map)\n","\n","# \"EmployerSize\" Mapping\n","employersize_map = {'I prefer not to answer': 0, \"I don't know\": 1, 'Fewer than 10 employees': 2,'10 to 19 employees': 3, \n","                 '20 to 99 employees': 4, '100 to 499 employees': 5,'500 to 999 employees': 6, '1,000 to 4,999 employees': 7, \n","                 '5,000 to 9,999 employees': 8,'10,000 or more employees':9}\n","train_df['EmployerSize'] = train_df['EmployerSize'].replace(employersize_map)\n","test_df['EmployerSize'] = test_df['EmployerSize'].replace(employersize_map)\n","\n","# \"WorkProductionFrequency\" Mapping\n","workproductionfrequency_map = {\"Don't know\": 0, 'Never': 1, 'Rarely': 2, 'Sometimes': 3, 'Most of the time': 4, 'Always':5}\n","train_df['WorkProductionFrequency'] = train_df['WorkProductionFrequency'].replace(workproductionfrequency_map)\n","test_df['WorkProductionFrequency'] = test_df['WorkProductionFrequency'].replace(workproductionfrequency_map)\n","\n","# \"WorkToolsFrequencyPython\" Mapping\n","worktoolsfrequencypython_map = {\"Rarely\":0, \"Sometimes\":1, \"Often\":2, \"Most of the time\":3}\n","train_df['WorkToolsFrequencyPython'] = train_df['WorkToolsFrequencyPython'].replace(worktoolsfrequencypython_map)\n","test_df['WorkToolsFrequencyPython'] = test_df['WorkToolsFrequencyPython'].replace(worktoolsfrequencypython_map)\n","\n","# \"WorkDataVisualizations\" Mapping\n","workdatavisualizations_map = {\"None\":0, \"Less than 10% of projects\":1, \"10-25% of projects\":2, \"26-50% of projects\":3,\n","                             \"51-75% of projects\":4, \"76-99% of projects\":5, \"100% of projects\":6}\n","train_df['WorkDataVisualizations'] = train_df['WorkDataVisualizations'].replace(workdatavisualizations_map)\n","test_df['WorkDataVisualizations'] = test_df['WorkDataVisualizations'].replace(workdatavisualizations_map)\n","\n","# \"RemoteWork\" Mapping\n","remotework_map = {\"Never\":0, \"Don't know\":1, \"Rarely\":2, \"Sometimes\":3, \"Most of the time\":4,\n","                 \"Always\":5}\n","train_df['RemoteWork'] = train_df['RemoteWork'].replace(remotework_map)\n","test_df['RemoteWork'] = test_df['RemoteWork'].replace(remotework_map)\n","\n","# Oridnal Features Mapping # 1\n","ordinalfeature_map = {\"Zero\":0, 'Rarely':1,'Sometimes':2, 'Often':3, 'Most of the time':4}\n","ordinalcolumns = [\"WorkToolsFrequencyPython\", \"WorkToolsFrequencyR\", \"WorkToolsFrequencySQL\", \"WorkMethodsFrequencyCross-Validation\",\n","                 \"WorkMethodsFrequencyDataVisualization\", \"WorkMethodsFrequencyDecisionTrees\", \"WorkMethodsFrequencyLogisticRegression\",\n","                 \"WorkMethodsFrequencyNeuralNetworks\", \"WorkMethodsFrequencyNeuralNetworks\", \"WorkMethodsFrequencyPCA\",\n","                 \"WorkMethodsFrequencyRandomForests\", \"WorkMethodsFrequencyTimeSeriesAnalysis\", \"WorkChallengeFrequencyPolitics\",\n","                 \"WorkChallengeFrequencyUnusedResults\", \"WorkChallengeFrequencyDirtyData\", \"WorkChallengeFrequencyExplaining\", \"WorkChallengeFrequencyTalent\",\n","                 \"WorkChallengeFrequencyClarity\", \"WorkChallengeFrequencyDataAccess\"]\n","\n","train_df[ordinalcolumns] = train_df[ordinalcolumns].replace(ordinalfeature_map)\n","test_df[ordinalcolumns] = test_df[ordinalcolumns].replace(ordinalfeature_map)\n","\n","# Ordinal Features Mapping # 2\n","ordinalfeature_map_two = {\"Zero\":0, \"Not Useful\":1,'Somewhat useful':2, 'Very useful':3,}\n","ordinalcolumns_two = [\"LearningPlatformUsefulnessBlogs\", \"LearningPlatformUsefulnessKaggle\", \"LearningPlatformUsefulnessCourses\", \n","                      \"LearningPlatformUsefulnessProjects\", \"LearningPlatformUsefulnessSO\", \"LearningPlatformUsefulnessTextbook\",\n","                      \"LearningPlatformUsefulnessYouTube\"]\n","train_df[ordinalcolumns_two] = train_df[ordinalcolumns_two].replace(ordinalfeature_map_two)\n","test_df[ordinalcolumns_two] = test_df[ordinalcolumns_two].replace(ordinalfeature_map_two)"],"execution_count":44,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2. Categorical Variables - to Dummy Variables"]},{"metadata":{},"cell_type":"markdown","source":["### New Feature Creation - PreferredWorkMatch\n","##### If the ML techniques that kagglers feel most competent also match with algoritms they used the most during their daily jobs\n","##### Give a score to the kaggler according to the number of matches"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def train_data():\n","    technique_select = train_df[\"MLTechniquesSelect\"].str.split(pat=\",\")\n","    work_algo_select = train_df[\"WorkAlgorithmsSelect\"].str.split(pat=\",\")\n","    score_arr = []\n","\n","    for i in range(0, 5529):\n","        score = 0\n","        try:\n","            if len(technique_select[i]) >= 1:\n","                for j in range(0, len(technique_select[i])):\n","                    for k in range(0, len(work_algo_select[i])):\n","                        if(technique_select[i][j] == work_algo_select[i][k]):\n","                            score += 1\n","            else:\n","                score = 0\n","        except:\n","            pass\n","        score_arr.append(score)\n","    train_df.insert(1, \"PreferredWorkMatch\", score_arr, True)\n","\n","def test_data():\n","    technique_select = test_df[\"MLTechniquesSelect\"].str.split(pat=\",\")\n","    work_algo_select = test_df[\"WorkAlgorithmsSelect\"].str.split(pat=\",\")\n","    score_arr = []\n","\n","    for i in range(0, 1000):\n","        score = 0\n","        try:\n","            if len(technique_select[i]) >= 1:\n","                for j in range(0, len(technique_select[i])):\n","                    for k in range(0, len(work_algo_select[i])):\n","                        if(technique_select[i][j] == work_algo_select[i][k]):\n","                            score += 1\n","            else:\n","                score = 0\n","        except:\n","            pass\n","        score_arr.append(score)\n","    test_df.insert(1, \"PreferredWorkMatch\", score_arr, True) \n","train_data()\n","test_data()"],"execution_count":45,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Multi Label Binzarizer"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Splitting categorical variables with multiple entries in a single row seperated with \",\"\n","from sklearn.preprocessing import MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()\n","\n","mlb_CurrentEmployerType_train = pd.DataFrame(mlb.fit_transform(train_df['CurrentEmployerType'].str.split(',')),columns=mlb.classes_)\n","train_df = pd.merge(train_df, mlb_CurrentEmployerType_train, right_index=True, left_index=True)\n","mlb_CurrentEmployer_test = pd.DataFrame(mlb.transform(test_df['CurrentEmployerType'].str.split(',')),columns=mlb.classes_)\n","test_df = pd.merge(test_df, mlb_CurrentEmployer_test, right_index=True, left_index=True)\n","\n","mlb_PastJobTitlesSelect_train = pd.DataFrame(mlb.fit_transform(train_df['PastJobTitlesSelect'].str.split(',')),columns=mlb.classes_)\n","train_df = pd.merge(train_df, mlb_PastJobTitlesSelect_train, right_index=True, left_index=True)\n","mlb_PastJobTitlesSelectr_test = pd.DataFrame(mlb.transform(test_df['PastJobTitlesSelect'].str.split(',')),columns=mlb.classes_)\n","test_df = pd.merge(test_df, mlb_PastJobTitlesSelectr_test, right_index=True, left_index=True)\n","\n","mlb_MLSkillsSelect_train = pd.DataFrame(mlb.fit_transform(train_df['MLSkillsSelect'].str.split(',')),columns=mlb.classes_)\n","train_df = pd.merge(train_df, mlb_MLSkillsSelect_train, right_index=True, left_index=True)\n","mlb_MLSkillsSelect_test = pd.DataFrame(mlb.transform(test_df['MLSkillsSelect'].str.split(',')),columns=mlb.classes_)\n","test_df = pd.merge(test_df, mlb_MLSkillsSelect_test, right_index=True, left_index=True)\n","\n","mlb_MLTechniquesSelect_train = pd.DataFrame(mlb.fit_transform(train_df['MLTechniquesSelect'].str.split(',')),columns=mlb.classes_)\n","train_df = pd.merge(train_df, mlb_MLTechniquesSelect_train, right_index=True, left_index=True)\n","mlb_MLTechniquesSelect_test = pd.DataFrame(mlb.transform(test_df['MLTechniquesSelect'].str.split(',')),columns=mlb.classes_)\n","test_df = pd.merge(test_df, mlb_MLTechniquesSelect_test, right_index=True, left_index=True)\n","\n","mlb_WorkAlgorithmsSelect_train = pd.DataFrame(mlb.fit_transform(train_df['WorkAlgorithmsSelect'].str.split(',')),columns=mlb.classes_)\n","train_df = pd.merge(train_df, mlb_WorkAlgorithmsSelect_train, right_index=True, left_index=True)\n","mlb_WorkAlgorithmsSelect_test = pd.DataFrame(mlb.transform(test_df['WorkAlgorithmsSelect'].str.split(',')),columns=mlb.classes_)\n","test_df = pd.merge(test_df, mlb_WorkAlgorithmsSelect_test, right_index=True, left_index=True)\n","\n","# Drop original columns\n","train_df = train_df.drop(columns=[\"CurrentEmployerType\", \"PastJobTitlesSelect\", \"MLSkillsSelect\", \"MLTechniquesSelect\", \"WorkAlgorithmsSelect\"])\n","test_df = test_df.drop(columns=[\"CurrentEmployerType\", \"PastJobTitlesSelect\", \"MLSkillsSelect\", \"MLTechniquesSelect\", \"WorkAlgorithmsSelect\"])"],"execution_count":46,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### One Hot Encoder"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# One Hot Encoding for categorical variables\n","from sklearn.preprocessing import OneHotEncoder\n","\n","enc = OneHotEncoder(handle_unknown='ignore')\n","\n","# Train Dataset\n","dummies_train = enc.fit_transform(train_df[[\"WorkMLTeamSeatSelect\", \"EmployerIndustry\", \"MajorSelect\", \"DataScienceIdentitySelect\", \n","                                            \"CurrentJobTitleSelect\", \"EmploymentStatus\", \"Country\", \"GenderSelect\", \"MLToolNextYearSelect\",\n","                                           \"MLMethodNextYearSelect\", \"LanguageRecommendationSelect\", \"WorkInternalVsExternalTools\"]]).toarray()\n","dummies_train = pd.DataFrame(dummies_train)\n","train_df = pd.merge(train_df, dummies_train, right_index=True, left_index=True)\n","train_df = train_df.drop(columns=[\"WorkMLTeamSeatSelect\", \"EmployerIndustry\", \"MajorSelect\", \"DataScienceIdentitySelect\", \n","                                  \"CurrentJobTitleSelect\", \"EmploymentStatus\", \"Country\", \"GenderSelect\", \"MLToolNextYearSelect\", \n","                                  \"MLMethodNextYearSelect\", \"LanguageRecommendationSelect\", \"WorkInternalVsExternalTools\"])\n","\n","# Test Dataset\n","dummies_test = enc.transform(test_df[[\"WorkMLTeamSeatSelect\", \"EmployerIndustry\", \"MajorSelect\",\"DataScienceIdentitySelect\", \n","                                      \"CurrentJobTitleSelect\", \"EmploymentStatus\", \"Country\", \"GenderSelect\", \"MLToolNextYearSelect\",\n","                                     \"MLMethodNextYearSelect\", \"LanguageRecommendationSelect\", \"WorkInternalVsExternalTools\"]]).toarray()\n","dummies_test = pd.DataFrame(dummies_train)\n","test_df = pd.merge(test_df, dummies_test, right_index=True, left_index=True)\n","test_df = test_df.drop(columns=[\"WorkMLTeamSeatSelect\", \"EmployerIndustry\", \"MajorSelect\", \"DataScienceIdentitySelect\", \n","                                \"CurrentJobTitleSelect\", \"EmploymentStatus\", \"Country\", \"GenderSelect\", \"MLToolNextYearSelect\",\n","                                \"MLMethodNextYearSelect\", \"LanguageRecommendationSelect\", \"WorkInternalVsExternalTools\"])"],"execution_count":47,"outputs":[]},{"metadata":{"_uuid":"f0a33011-b9e7-4041-b13d-ad4593f90b7b","_cell_guid":"ccfcf701-09d8-4b4a-9807-5d07a9e2c95a","trusted":true},"cell_type":"code","source":["# Head of the dataset after all the data processing done in train data\n","train_df.head()"],"execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"   PreferredWorkMatch   Age  TitleFit  LearningPlatformUsefulnessBlogs  \\\n0                   0  28.0         1                                0   \n1                   1  26.0         0                                2   \n2                   0  34.0         1                                3   \n3                   0  33.0         1                                0   \n4                   1  35.0         1                                0   \n\n   LearningPlatformUsefulnessKaggle  LearningPlatformUsefulnessCourses  \\\n0                                 0                                  3   \n1                                 3                                  0   \n2                                 0                                  2   \n3                                 0                                  3   \n4                                 3                                  2   \n\n   LearningPlatformUsefulnessProjects  LearningPlatformUsefulnessSO  \\\n0                                   0                             0   \n1                                   0                             0   \n2                                   0                             0   \n3                                   0                             2   \n4                                   0                             0   \n\n   LearningPlatformUsefulnessTextbook  LearningPlatformUsefulnessYouTube  ...  \\\n0                                   0                                  1  ...   \n1                                   3                                  0  ...   \n2                                   2                                  2  ...   \n3                                   0                                  0  ...   \n4                                   3                                  0  ...   \n\n   198  199  200  201  202  203  204  205  206  207  \n0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n\n[5 rows x 310 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PreferredWorkMatch</th>\n      <th>Age</th>\n      <th>TitleFit</th>\n      <th>LearningPlatformUsefulnessBlogs</th>\n      <th>LearningPlatformUsefulnessKaggle</th>\n      <th>LearningPlatformUsefulnessCourses</th>\n      <th>LearningPlatformUsefulnessProjects</th>\n      <th>LearningPlatformUsefulnessSO</th>\n      <th>LearningPlatformUsefulnessTextbook</th>\n      <th>LearningPlatformUsefulnessYouTube</th>\n      <th>...</th>\n      <th>198</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>204</th>\n      <th>205</th>\n      <th>206</th>\n      <th>207</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>34.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>33.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 310 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"7dd26821-9d19-48e0-9fe9-07eec1c2a1d5","_cell_guid":"71229e42-88ed-4a47-90b8-e30de99f87c7","trusted":true},"cell_type":"code","source":["# Head of the dataset after all the data processing done in test data\n","test_df.head()"],"execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"   PreferredWorkMatch   Age  TitleFit  LearningPlatformUsefulnessBlogs  \\\n0                   0  59.0         2                                3   \n1                   1  30.0         1                                3   \n2                   0  19.0         1                                3   \n3                   0  50.0         1                                0   \n4                   0  35.0         2                                3   \n\n   LearningPlatformUsefulnessKaggle  LearningPlatformUsefulnessCourses  \\\n0                                 2                                  3   \n1                                 3                                  0   \n2                                 3                                  0   \n3                                 2                                  0   \n4                                 3                                  3   \n\n   LearningPlatformUsefulnessProjects  LearningPlatformUsefulnessSO  \\\n0                                   3                             2   \n1                                   3                             0   \n2                                   0                             0   \n3                                   3                             3   \n4                                   3                             2   \n\n   LearningPlatformUsefulnessTextbook  LearningPlatformUsefulnessYouTube  ...  \\\n0                                   3                                  2  ...   \n1                                   0                                  0  ...   \n2                                   0                                  0  ...   \n3                                   0                                  0  ...   \n4                                   2                                  3  ...   \n\n   198  199  200  201  202  203  204  205  206  207  \n0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n\n[5 rows x 309 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PreferredWorkMatch</th>\n      <th>Age</th>\n      <th>TitleFit</th>\n      <th>LearningPlatformUsefulnessBlogs</th>\n      <th>LearningPlatformUsefulnessKaggle</th>\n      <th>LearningPlatformUsefulnessCourses</th>\n      <th>LearningPlatformUsefulnessProjects</th>\n      <th>LearningPlatformUsefulnessSO</th>\n      <th>LearningPlatformUsefulnessTextbook</th>\n      <th>LearningPlatformUsefulnessYouTube</th>\n      <th>...</th>\n      <th>198</th>\n      <th>199</th>\n      <th>200</th>\n      <th>201</th>\n      <th>202</th>\n      <th>203</th>\n      <th>204</th>\n      <th>205</th>\n      <th>206</th>\n      <th>207</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>59.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>30.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>19.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 309 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"142e5f90-3579-4dd3-aa1d-f6fa5a050b36","_cell_guid":"29e91365-bb5d-4283-aa8e-de507acf59ec","trusted":true},"cell_type":"markdown","source":["## Model Selection"]},{"metadata":{"_uuid":"b90aff76-f540-47c0-b6ca-c6e26b8ac40b","_cell_guid":"bed180e7-606a-43b8-8605-7e19c76ef3e0","trusted":true},"cell_type":"code","source":["from sklearn.metrics import mean_squared_error # to calculate root of mean squared error\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import cross_val_predict # to predict\n","\n","x_train = train_df.drop(['JobSatisfaction'], axis=1)\n","y_train = train_df[\"JobSatisfaction\"].values"],"execution_count":50,"outputs":[]},{"metadata":{"_uuid":"03d884a8-bcc5-4c02-a360-3c391b856106","_cell_guid":"57ad5181-e920-4f6c-a9ec-06e705d413a1","trusted":true},"cell_type":"markdown","source":["### SVR Regression"]},{"metadata":{"_uuid":"f752eaa0-0400-4c4a-905c-e2c56fa445e4","_cell_guid":"894fc225-aabc-4a87-adb9-df84b85cc148","trusted":true},"cell_type":"code","source":["\"\"\"from sklearn.svm import SVR\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import cross_val_predict\n","\n","# Instantiation \n","regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, kernel=\"linear\"))\n","\n","# Fitting the model \n","regr.fit(x_train, y_train)\n","\n","# Predict the model\n","#y_pred = regr.predict(X_val)\n","y_pred = cross_val_predict(regr, x_train, y_train, cv=2)\n","\n","# RMSE Computation\n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse))\n","\n","# Output to CSV\n","test_pred = regr.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_svr_reg.csv\", index=False)\"\"\""],"execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"'from sklearn.svm import SVR\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import cross_val_predict\\n\\n# Instantiation \\nregr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, kernel=\"linear\"))\\n\\n# Fitting the model \\nregr.fit(x_train, y_train)\\n\\n# Predict the model\\n#y_pred = regr.predict(X_val)\\ny_pred = cross_val_predict(regr, x_train, y_train, cv=2)\\n\\n# RMSE Computation\\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse))\\n\\n# Output to CSV\\ntest_pred = regr.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_svr_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{"_uuid":"c89328a1-d7cc-40c1-9e79-d6174193ffc1","_cell_guid":"7ac8b3fd-e12f-4c33-8246-0905150de74a","trusted":true},"cell_type":"markdown","source":["### Linear Regresion"]},{"metadata":{"_uuid":"8de388b9-e01b-4fb2-aa9a-e72f1f90e28d","_cell_guid":"60edb11e-1876-4fb8-8d7f-2e2381cb2dd7","trusted":true},"cell_type":"code","source":["\"\"\"from sklearn.linear_model import LinearRegression\n","\n","# Instantiation \n","reg = LinearRegression()\n","\n","# Fitting the model \n","reg.fit(x_train, y_train)\n","\n","#print(cross_val_score(reg, x_train, y_train, cv=5))\n","\n","# Predict the model\n","#y_pred = reg.predict(X_val)\n","y_pred = cross_val_predict(reg, x_train, y_train, cv=10)\n","\n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_linear_reg.csv\", index=False)\"\"\""],"execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"'from sklearn.linear_model import LinearRegression\\n\\n# Instantiation \\nreg = LinearRegression()\\n\\n# Fitting the model \\nreg.fit(x_train, y_train)\\n\\n#print(cross_val_score(reg, x_train, y_train, cv=5))\\n\\n# Predict the model\\n#y_pred = reg.predict(X_val)\\ny_pred = cross_val_predict(reg, x_train, y_train, cv=10)\\n\\n# RMSE Computation \\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse)) \\n\\n# Output to CSV\\ntest_pred = reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_linear_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### SGD Regressor"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"from sklearn.linear_model import SGDRegressor\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","# Always scale the input. The most convenient way is to use a pipeline.\n","reg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))\n","\n","# Fitting the model \n","reg.fit(x_train, y_train)\n","\n","# Predict the model\n","#y_pred = reg.predict(X_val)\n","y_pred = cross_val_predict(reg, x_train, y_train, cv=3)\n","\n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_sgd_reg.csv\", index=False)\"\"\""],"execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"'from sklearn.linear_model import SGDRegressor\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Always scale the input. The most convenient way is to use a pipeline.\\nreg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))\\n\\n# Fitting the model \\nreg.fit(x_train, y_train)\\n\\n# Predict the model\\n#y_pred = reg.predict(X_val)\\ny_pred = cross_val_predict(reg, x_train, y_train, cv=3)\\n\\n# RMSE Computation \\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse)) \\n\\n# Output to CSV\\ntest_pred = reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_sgd_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### Elastic Net Regressor"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"from sklearn.linear_model import ElasticNet\n","from sklearn.datasets import make_regression\n","\n","# Instantiation \n","regr = ElasticNet(random_state=0)\n","\n","# Fitting the model\n","regr.fit(x_train, y_train)\n","\n","# Predict the model\n","#y_pred = reg.predict(X_val)\n","y_pred = cross_val_predict(reg, x_train, y_train, cv=2)\n","\n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_elasticnet_reg.csv\", index=False)\"\"\""],"execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"'from sklearn.linear_model import ElasticNet\\nfrom sklearn.datasets import make_regression\\n\\n# Instantiation \\nregr = ElasticNet(random_state=0)\\n\\n# Fitting the model\\nregr.fit(x_train, y_train)\\n\\n# Predict the model\\n#y_pred = reg.predict(X_val)\\ny_pred = cross_val_predict(reg, x_train, y_train, cv=2)\\n\\n# RMSE Computation \\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse)) \\n\\n# Output to CSV\\ntest_pred = reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_elasticnet_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### Bayesian Ridge Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"from sklearn import linear_model\n","\n","# Instantiation \n","reg = linear_model.BayesianRidge()\n","\n","# Fitting the model\n","reg.fit(x_train, y_train)\n","\n","# Predict the model\n","#y_pred = reg.predict(X_val)\n","y_pred = cross_val_predict(reg, x_train, y_train, cv=5)\n","\n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_bayessianridge_reg.csv\", index=False)\"\"\""],"execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"'from sklearn import linear_model\\n\\n# Instantiation \\nreg = linear_model.BayesianRidge()\\n\\n# Fitting the model\\nreg.fit(x_train, y_train)\\n\\n# Predict the model\\n#y_pred = reg.predict(X_val)\\ny_pred = cross_val_predict(reg, x_train, y_train, cv=5)\\n\\n# RMSE Computation \\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse)) \\n\\n# Output to CSV\\ntest_pred = reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_bayessianridge_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### XGBoost Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"import xgboost as xgb\n","  \n","# Instantiation \n","xgb_r = xgb.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 42,\n","                            max_depth=2, gamma=2, eta=0.8,reg_alpha=0.5,\n","                         reg_lambda=0.5) \n","  \n","# Fitting the model \n","xgb_r.fit(x_train, y_train) \n","  \n","# Predict the model \n","#y_pred = xgb_r.predict(X_val)\n","y_pred = cross_val_predict(xgb_r, x_train, y_train, cv=10)\n","  \n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = xgb_r.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_xgboost_reg.csv\", index=False)\"\"\""],"execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"'import xgboost as xgb\\n  \\n# Instantiation \\nxgb_r = xgb.XGBRegressor(objective =\\'reg:linear\\', n_estimators = 10, seed = 42,\\n                            max_depth=2, gamma=2, eta=0.8,reg_alpha=0.5,\\n                         reg_lambda=0.5) \\n  \\n# Fitting the model \\nxgb_r.fit(x_train, y_train) \\n  \\n# Predict the model \\n#y_pred = xgb_r.predict(X_val)\\ny_pred = cross_val_predict(xgb_r, x_train, y_train, cv=10)\\n  \\n# RMSE Computation \\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse)) \\n\\n# Output to CSV\\ntest_pred = xgb_r.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_xgboost_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### k-NN Regressor"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"from sklearn.neighbors import KNeighborsRegressor\n","\n","# Instantiation \n","neigh_reg = KNeighborsRegressor(n_neighbors=100)\n","\n","# Fitting the model \n","neigh_reg.fit(x_train, y_train)\n","\n","# Predict the model\n","#y_pred = neigh_reg.predict(X_val)\n","y_pred = cross_val_predict(neigh_reg, x_train, y_train, cv=3)\n","\n","# RMSE Computation\n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse))\n","\n","# Output to CSV\n","test_pred = neigh_reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_knn_reg.csv\", index=False)\"\"\""],"execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"'from sklearn.neighbors import KNeighborsRegressor\\n\\n# Instantiation \\nneigh_reg = KNeighborsRegressor(n_neighbors=100)\\n\\n# Fitting the model \\nneigh_reg.fit(x_train, y_train)\\n\\n# Predict the model\\n#y_pred = neigh_reg.predict(X_val)\\ny_pred = cross_val_predict(neigh_reg, x_train, y_train, cv=3)\\n\\n# RMSE Computation\\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse))\\n\\n# Output to CSV\\ntest_pred = neigh_reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_knn_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### Stochastic Gradient Boosting Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"# Stochastic Gradient Boosting Regression\n","from sklearn import model_selection\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","# Instantiation \n","seed = 7\n","num_trees = 100\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","gradient_reg = GradientBoostingRegressor(n_estimators=num_trees, random_state=seed)\n","results = model_selection.cross_val_score(gradient_reg, x_train, y_train, cv=kfold)\n","print(results.mean())\n","\n","# Fitting the model \n","gradient_reg.fit(x_train, y_train)\n","\n","# Predict the model\n","#y_pred = gradient_reg.predict(X_val)\n","y_pred = cross_val_predict(gradient_reg, x_train, y_train, cv=10)\n","\n","# RMSE Computation\n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse))\n","\n","# Output to CSV\n","test_pred = gradient_reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_sgb_reg_cv10.csv\", index=False)\"\"\""],"execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"'# Stochastic Gradient Boosting Regression\\nfrom sklearn import model_selection\\nfrom sklearn.ensemble import GradientBoostingRegressor\\n\\n# Instantiation \\nseed = 7\\nnum_trees = 100\\nkfold = model_selection.KFold(n_splits=10, random_state=seed)\\ngradient_reg = GradientBoostingRegressor(n_estimators=num_trees, random_state=seed)\\nresults = model_selection.cross_val_score(gradient_reg, x_train, y_train, cv=kfold)\\nprint(results.mean())\\n\\n# Fitting the model \\ngradient_reg.fit(x_train, y_train)\\n\\n# Predict the model\\n#y_pred = gradient_reg.predict(X_val)\\ny_pred = cross_val_predict(gradient_reg, x_train, y_train, cv=10)\\n\\n# RMSE Computation\\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse))\\n\\n# Output to CSV\\ntest_pred = gradient_reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_sgb_reg_cv10.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### Random Forest Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["\"\"\"from sklearn.ensemble import RandomForestRegressor\n","from sklearn.datasets import make_regression\n","\n","# Instantiation \n","random_forest_reg = RandomForestRegressor(max_depth=2, random_state=0)\n","\n","# Fitting the model \n","random_forest_reg.fit(x_train, y_train)\n","\n","# Predict the model \n","#y_pred = xgb_r.predict(X_val)\n","y_pred = cross_val_predict(random_forest_reg, x_train, y_train, cv=5)\n","  \n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = random_forest_reg.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_random_forest_reg.csv\", index=False)\"\"\""],"execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"'from sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.datasets import make_regression\\n\\n# Instantiation \\nrandom_forest_reg = RandomForestRegressor(max_depth=2, random_state=0)\\n\\n# Fitting the model \\nrandom_forest_reg.fit(x_train, y_train)\\n\\n# Predict the model \\n#y_pred = xgb_r.predict(X_val)\\ny_pred = cross_val_predict(random_forest_reg, x_train, y_train, cv=5)\\n  \\n# RMSE Computation \\nrmse = mean_squared_error(y_train, y_pred, squared=False)\\nprint(\"RMSE:% f\" %(rmse)) \\n\\n# Output to CSV\\ntest_pred = random_forest_reg.predict(test_df)\\npred_df[\"Prediction\"] = test_pred\\npred_df.to_csv(\"prediction_random_forest_reg.csv\", index=False)'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### Ensemble Voting Regression"]},{"metadata":{"trusted":true},"cell_type":"code","source":["from sklearn import model_selection\n","import xgboost as xgb\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn import linear_model\n","from sklearn.ensemble import VotingRegressor\n","\n","# Create the sub models\n","model1 = xgb.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 42,\n","                            max_depth=2, gamma=2, eta=0.8,reg_alpha=0.5,\n","                         reg_lambda=0.5)\n","model2 = GradientBoostingRegressor(n_estimators=100, random_state=7)\n","model3 = linear_model.BayesianRidge()\n","\n","# Create the ensemble model\n","ensemble = VotingRegressor([(\"xgb\", model1), ('gb', model2), ('br', model3)])\n","\n","# Fitting the model \n","ensemble.fit(x_train, y_train)\n","\n","# Predict the model \n","y_pred = cross_val_predict(ensemble, x_train, y_train, cv=10)\n","  \n","# RMSE Computation \n","rmse = mean_squared_error(y_train, y_pred, squared=False)\n","print(\"RMSE:% f\" %(rmse)) \n","\n","# Output to CSV\n","test_pred = ensemble.predict(test_df)\n","pred_df[\"Prediction\"] = test_pred\n","pred_df.to_csv(\"prediction_ensamble_xgb_gradient_sgd.csv\", index=False)"],"execution_count":60,"outputs":[{"output_type":"stream","text":"[19:24:44] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:44] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:49] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:49] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:53] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:53] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:57] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:24:57] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:01] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:01] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:05] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:05] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:09] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:09] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:13] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:13] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:17] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:17] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:21] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:21] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:25] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[19:25:25] WARNING: ../src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\nRMSE: 1.938719\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}